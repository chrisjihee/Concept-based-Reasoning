We want to compare how well a large-scale language model (LLM) internally structures and stores knowledge through a knowledge graph (KG).
A knowledge graph typically represents knowledge in the form of a triple [format: subject -> relation -> object].
Where a relation is one of the following lists:
{relations}

Here are some demo examples of such a knowledge graph.

<BEGIN_OF_DEMO_EXAMPLE>
* Target entity: {demo_entity}
* A set of triples where the subject is the target entity (quantity: {demo_triples_size}):
{demo_triples}
<END_OF_DEMO_EXAMPLE>

Now we want to test your knowledge structuring ability with this knowledge graph construction ability.
Let's output a set of triples where the subject is the target entity, referring to the demo examples above.

<BEGIN_OF_YOUR_OUTPUT>
* Target entity: {test_entity}
* A set of triples whose subject is the target entity{output_triples_hint}:
{output_triples}
<END_OF_YOUR_OUTPUT>